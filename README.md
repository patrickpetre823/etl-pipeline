# etl-pipeline
Small project to learn basics of airflow and etl pipeline creation


1. Create folders and set uid
2. curl compose file
3. celeryworker to local
4. delete celery lines
5. load_examples = "false"
6. delete redis
7. delete worker
8. delete dependency of redis
9. comment out image and use costum build .
10. create dockerfile
11. fill dockerfile from airflow docs
12. delete the airflow version in it
13. create requirements
14. remove triggerer in compose
15. add .gitignore + api-key
16. add make_df
17. add retrieval time + pytz for timezone
18. add retrieval date
19. added DB
20. 
